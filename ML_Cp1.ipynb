{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 7 color = steelblue> Machine Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital = pd.read_csv(\"Hospitalisation details.csv\")\n",
    "Medical = pd.read_csv(\"Medical Examinations.csv\")\n",
    "names = pd.read_excel('Names.xlsx')\n",
    "hospital.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Medical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(hospital,Medical,how = 'outer',on = 'Customer ID')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('?',np.nan)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NumberOfMajorSurgeries'] = data['NumberOfMajorSurgeries'].replace(\"No major surgery\",0)\n",
    "data['NumberOfMajorSurgeries'] = data['NumberOfMajorSurgeries'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes[data.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.year = data.year.astype(int)\n",
    "data.dtypes[data.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = data.corr(numeric_only=True)\n",
    "data_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_corr,annot=True,fmt = '.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unnessesory column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "date.today().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = date.today().year - data['year']\n",
    "data1 = data.drop(columns =['Customer ID','month','date','year'])\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical data into numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split as split, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "for i in data1.dtypes[data1.dtypes == 'object'].index:\n",
    "    k = (data1[i].unique().tolist())\n",
    "    enc = OrdinalEncoder(categories=[k],dtype=int)\n",
    "    data1[i] = enc.fit_transform(data1[[i]])\n",
    "\n",
    "data1.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "ridge = Ridge(random_state=12)\n",
    "\n",
    "X = data1.drop(columns='charges')\n",
    "y = data1.charges\n",
    "X_train,X_test,y_train,y_test = split(X,y,test_size=0.2,random_state=12)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred = lr.predict(X_train)\n",
    "lr_test_pred = lr.predict(X_test)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Linear Regression for Train set Score is: {lr.score(X_train,y_train) * 100:.4f}%\")\n",
    "print(f\"Linear Regression for Test set Score is : {lr.score(X_test,y_test) * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE Lr for Train:' ,(mean_squared_error(y_true = y_train,y_pred = lr_train_pred).round(2)))\n",
    "print(f\"R Square Lr for Train: {r2_score(y_train,lr_train_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_train_pred = ridge.predict(X_train)\n",
    "ridge_test_pred = ridge.predict(X_test)\n",
    "print(ridge.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ridge Regression Train Score is: {ridge.score(X_train,y_train) * 100:.4f}%\")\n",
    "print(f\"Ridge Regression Test Score is : {ridge.score(X_test,y_test) * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE Ridge for Train:' ,(mean_squared_error(y_true = y_train,y_pred = ridge_train_pred).round(2)))\n",
    "print(f\"R Square Ridge for Train: {r2_score(y_train,ridge_train_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified 5 fold cross validation with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = data1.drop(columns='smoker')\n",
    "y = data1.smoker\n",
    "X_train,X_test,y_train,y_test = split(X,y,test_size=0.2,random_state=12)\n",
    "\n",
    "model = LogisticRegression(max_iter = 10000)\n",
    "skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=12)\n",
    "cv_scores = cross_val_score(model,X_train,y_train,cv = skfold)\n",
    "for fold,score in enumerate(cv_scores):\n",
    "    print(f\"Fold {fold + 1} for cross val score is:{score*100:.2f}%\")\n",
    "print()    \n",
    "print(f\"Mean Cross Val Score: {cv_scores.mean()*100:.2f}%\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization techniques and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.drop(columns='charges')\n",
    "y = data1.charges\n",
    "X_train,X_test,y_train,y_test = split(X,y,test_size=0.2,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train_sc = sc.fit_transform(X_train)\n",
    "x_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "models = {\"StandardScaler\" : StandardScaler(),\n",
    "\"MinMaxScaler\" : MinMaxScaler(),\n",
    "\"RobustScaler\" : RobustScaler()}\n",
    "rf = RandomForestRegressor()\n",
    "for model,item in models.items():\n",
    "    x_train_model = item.fit_transform(X_train)\n",
    "    x_test_model = item.transform(X_test)\n",
    "    rf.fit(x_train_model,y_train)\n",
    "    print(f\"Train Score for {model}: {rf.score(x_train_model,y_train)*100:.2f}%\")\n",
    "    print(f\"Test Score for {model} : {rf.score(x_test_model,y_test)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[10,100,50,200],'criterion':['absolute_error', 'squared_error', 'friedman_mse', 'poisson'],'max_depth':[1,10,20],\n",
    "              'min_samples_split':[2,4,5,8,10],'min_samples_leaf':[1,2,3,4,6],'max_features':['sqrt','log2'],\n",
    "              'ccp_alpha':[0,0.2,0.5,1]}\n",
    "random_rf = RandomizedSearchCV(estimator=RandomForestRegressor(),param_distributions=param_grid,cv = 5,n_jobs=-1)\n",
    "random_rf.fit(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random_rf = random_rf.predict(x_train_sc)\n",
    "y_test_random_rf = random_rf.predict(x_test_sc)\n",
    "print(f\"Train Performance after tune: {random_rf.score(x_train_sc,y_train)*100:.2f}%\")\n",
    "print(f\"Test Performance after tune: {random_rf.score(x_test_sc,y_test)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressions Tunning for KNeighbor, SGD, Random Forest with Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'RandomForest':RandomForestRegressor(random_state=12),'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "          'SGDRegressor':SGDRegressor()}\n",
    "#gb = GridSearchCV()\n",
    "param_grids = {'param_knn': {'weights' : ['uniform', 'distance'],'algorithm':['auto', 'ball_tree',\n",
    "              'kd_tree', 'brute'],'leaf_size':[20,50,40,30]},\n",
    "              'param_rf': {'n_estimators':[10,100,50,200],'criterion':['squared_error', 'absolute_error', 'friedman_mse',\n",
    "                'poisson'],'max_depth':[1,10,20],'min_samples_split':[2,4,5,8,10],'min_samples_leaf':[1,2,3,4,6],\n",
    "                'max_features':['sqrt','log2'],'ccp_alpha':[0,0.2,0.5,1]},\n",
    "              'param_sgd': {'tol' : [0.001,0.0001,0.01],'alpha':[0.001,0.0001,0.01,0.1],'l1_ratio':[0.15,0.3,0.5],\n",
    "                'max_iter':[30000,10000,50000,20000],'epsilon':[0.1,0.01,0.3,0.5]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in param_grids.items():\n",
    "    for model, item in models.items():\n",
    "        if param == param_grids.get('param_rf') and model == 'RandomForest':\n",
    "            print(f\"   For {model} Model\")\n",
    "            print(f\"Best param for {model}\")\n",
    "            rnd = RandomizedSearchCV(estimator=item,param_distributions=param,cv = 5)\n",
    "            rnd.fit(x_train_sc,y_train)\n",
    "            display(rnd.best_params_)\n",
    "            print(f\"Performance score for {model} model: {rnd.best_score_*100:.2f}%\")\n",
    "        elif param == param_grids.get('param_knn') and model == 'KNeighborsRegressor':\n",
    "            print(f\"     For {model} Model\")\n",
    "            print(f\"Best param for {model}\")\n",
    "            rnd = RandomizedSearchCV(estimator=item,param_distributions=param,cv = 5)\n",
    "            rnd.fit(x_train_sc,y_train)\n",
    "            display(rnd.best_params_)\n",
    "            print(f\"Performance Score for {model} Model: {rnd.best_score_*100:.2f}%\")\n",
    "        elif param == param_grids.get('param_sgd') and model == 'SGDRegressor':\n",
    "            print(f\"     For {model} Model\")\n",
    "            print(f\"Best param for {model}\")\n",
    "            rnd = RandomizedSearchCV(estimator=item,param_distributions=param,cv = 5)\n",
    "            rnd.fit(x_train_sc,y_train)\n",
    "            display(rnd.best_params_)\n",
    "            print(f\"Performance Score for {model} Model: {rnd.best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.drop(columns='smoker')\n",
    "y = data1.smoker\n",
    "X_train,X_test,y_train,y_test = split(X,y,test_size=0.2,random_state=12)\n",
    "x_train_sc = sc.fit_transform(X_train)\n",
    "x_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers Tuning for Random Forest , SVC, Logistic with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'RandomForest':RandomForestClassifier(random_state=12),'SVC':SVC(random_state=12),\n",
    "          'LogisticRegression':LogisticRegression()}\n",
    "#gb = GridSearchCV()\n",
    "param_grids = {'param_svc': {'kernel': ['linear', 'poly', 'rbf'],'tol' : [0.001,0.0001,0.01],\n",
    "              'C':[0.1,1,0.5],'degree':[1,2,3,5,0],'gamma':['scale', 'auto'],\n",
    "              'max_iter':[30000,10000,50000,20000]},\n",
    "              'param_rf': {'n_estimators':[10,100,50,200],'criterion':['gini','entropy', 'log_loss'],'max_depth':[1,10,20],\n",
    "              'min_samples_split':[2,4,5,8,10],'min_samples_leaf':[1,2,3,4,6],'max_features':['sqrt','log2'],\n",
    "              'ccp_alpha':[0,0.2,0.5,1]},\n",
    "              'param_lg': {'tol' : [0.001,0.0001,0.01],'C':[0.1,1,0.5],\n",
    "                'max_iter':[30000,10000,50000,20000],'solver':['saga','liblinear']}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in param_grids.items():\n",
    "    for model, item in models.items():\n",
    "        if param == param_grids.get('param_rf') and model == 'RandomForest':\n",
    "            print(f\"   For {model} Model\")\n",
    "            print(f\"Best param for {model}\")\n",
    "            rnd = RandomizedSearchCV(estimator=item,param_distributions=param,cv = 5)\n",
    "            rnd.fit(x_train_sc,y_train)\n",
    "            display(rnd.best_params_)\n",
    "            print(f\"Performance score for {model} model: {rnd.best_score_*100:.2f}%\")\n",
    "        elif param == param_grids.get('param_svc') and model == 'SVC':\n",
    "            print(f\"     For {model} Model\")\n",
    "            print(f\"Best param for {model}\")\n",
    "            rnd = RandomizedSearchCV(estimator=item,param_distributions=param,cv = 5)\n",
    "            rnd.fit(x_train_sc,y_train)\n",
    "            display(rnd.best_params_)\n",
    "            print(f\"Performance Score for {model} Model: {rnd.best_score_*100:.2f}%\")\n",
    "        elif param == param_grids.get('param_lg') and model == 'LogisticRegression':\n",
    "            print(f\"     For {model} Model\")\n",
    "            print(f\"Best param for {model}\")\n",
    "            rnd = RandomizedSearchCV(estimator=item,param_distributions=param,cv = 5)\n",
    "            rnd.fit(x_train_sc,y_train)\n",
    "            display(rnd.best_params_)\n",
    "            print(f\"Performance Score for {model} Model: {rnd.best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn pipelines to streamline the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.drop(columns='charges')\n",
    "y = data1.charges\n",
    "X_train,X_test,y_train,y_test = split(X,y,test_size=0.2,random_state=12)\n",
    "x_train_sc = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0, 1))),\n",
    "    ('classifier', GradientBoostingRegressor(n_estimators=100, random_state=7))\n",
    "])\n",
    "\n",
    "# Evaluate the Gradient Boosting Classifier pipeline\n",
    "gb_results = cross_val_score(gb_pipeline, X_train, y_train, cv=10)\n",
    "print(f\"Gradient Boosting Classifier mean accuracy after cross validation:  {gb_results.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization techniques to address the bias-variance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "\n",
    "ridge_cv_model = RidgeCV(alphas=np.arange(0,10,0.1),cv = 5)\n",
    "ridge_cv_model.fit(X_train,y_train)\n",
    "ridge_alpha = ((ridge_cv_model.alpha_).round(2))\n",
    "ridge_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = LassoCV(cv = 5)\n",
    "lasso_cv_model.fit(X_train,y_train)\n",
    "lasso_best_alpha = (lasso_cv_model.alpha_).round(2)\n",
    "lasso_best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.arange(0.1,0.9,0.1)\n",
    "elastic_cv_model = ElasticNetCV(cv = 5,l1_ratio=l1)\n",
    "elastic_cv_model.fit(X_train,y_train)\n",
    "elastic_alpha = elastic_cv_model.alpha_\n",
    "elastic_cv_model.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Ridge':Ridge(alpha = ridge_alpha),'Lasso':Lasso(alpha = lasso_best_alpha),\n",
    "          'Elastic net':ElasticNet(alpha=elastic_alpha,l1_ratio=elastic_cv_model.l1_ratio_)}\n",
    "for model,item in models.items():\n",
    "    item.fit(X_train,y_train)\n",
    "    scores = cross_val_score(item,X_train,y_train,cv = 5)\n",
    "    print(f\"              Folds for {model}\")\n",
    "    for fold,score in enumerate(scores):   \n",
    "        print(f\"Fold {fold + 1} for cross val score for {model} is: {score*100:.2f}%\")\n",
    "    print(f\"Average cross-validation score for {model}: {np.mean(scores) * 100:.2f}%\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold Cross Validation for Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "fold = KFold(n_splits = 5,shuffle = True, random_state = 12)\n",
    "model = LinearRegression()\n",
    "cv_scores = cross_val_score(model,X_train,y_train,cv = fold)\n",
    "for fold,score in enumerate(cv_scores):\n",
    "    print(f\"Fold {fold + 1} for cross val score is:{score*100:.2f}%\")\n",
    "print()    \n",
    "print(f\"Mean Cross Val Score: {cv_scores.mean()*100:.2f}%\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold Cross Validation for Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = KFold(n_splits = 5,shuffle = True, random_state = 12)\n",
    "model = RandomForestRegressor()\n",
    "cv_scores = cross_val_score(model,X_train,y_train,cv = fold)\n",
    "for fold,score in enumerate(cv_scores):\n",
    "    print(f\"Fold {fold + 1} for cross val score is:{score*100:.2f}%\")\n",
    "print()    \n",
    "print(f\"Mean Cross Val Score: {cv_scores.mean()*100:.2f}%\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost model, variable importance scores, redundant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importance_scores = model.feature_importances_\n",
    "(importance_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Feature Importance Scores:\", importance_scores)\n",
    "feature_names = model.feature_names_in_\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Important of 5 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = pd.DataFrame(importance_scores,index=feature_names).rename(columns={0:'Imp_Features'}).sort_values('Imp_Features',ascending=False)\n",
    "feature_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the cost of hospitalization for Christopher, Ms. Jayna (Date of birth 12/28/1988; height 170 cm; and weight 85 kgs). She lives with her partner and two children in a tier-1 city, and her stateâ€™s State ID is R1011. She was found to be nondiabetic (HbA1c = 5.8). She smokes but is otherwise healthy. She has had no transplants or major surgeries. Her father died of lung cancer. Hospitalization costs will be estimated using tier-1 hospitals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({'children':[2],'Hospital tier':[0],'City tier':[2],'State ID':[6],'BMI':[29.41],'HBA1C':[5.8],\n",
    "                         'Heart Issues':[0],'Any Transplants':[0],'Cancer history':[0],'NumberOfMajorSurgeries':[0],\n",
    "                        'smoker':[1],'Age':[36]})\n",
    "new_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1.drop(columns='charges')\n",
    "y = data1.charges\n",
    "x_train,x_test,y_train,y_test = split(x,y,test_size=0.2,random_state=12)\n",
    "rf = RandomForestRegressor(n_estimators = 100,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 2,\n",
    " max_features= 'log2',\n",
    " max_depth= 10,\n",
    " ccp_alpha= 0)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = rf.predict(x_test)\n",
    "pred_train = rf.predict(x_train)\n",
    "print(f\"Train score:{rf.score(x_train,y_train)*100:.2f}% \" )\n",
    "print(f\"Test score:{rf.score(x_test,y_test)*100:.2f}% \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price = rf.predict(new_data)\n",
    "predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted hospitalization cost using the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'children':[0,2,1,4],'Hospital tier':[0,2,1,2],'City tier':[2,1,1,0],'State ID':[3,7,9,0],'BMI':[25,35,34,23],\n",
    "        'HBA1C':[3.5,6.9,5,4],'Heart Issues':[0,1,1,0],'Any Transplants':[0,0,0,1],'Cancer history':[1,0,0,0],\n",
    "        'NumberOfMajorSurgeries':[0,1,0,0],'smoker':[0,1,1,1],'Age':[34,56,28,36]}\n",
    "new_data = pd.DataFrame(dict)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "class HospitalizationCostPredictor:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Models Uses\n",
    "        self.models = {\n",
    "            'Linear Regression': self._create_pipeline(LinearRegression()),\n",
    "            'SVR': self._create_pipeline(SVR(kernel='linear',degree=5)),\n",
    "            'Lasso Regression': self._create_pipeline(Lasso(alpha=1.0)),\n",
    "            'Gradient Boosting': self._create_pipeline(GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "            'Random Forest': self._create_pipeline(RandomForestRegressor()),\n",
    "            'Decision Tree Regressor': self._create_pipeline(DecisionTreeRegressor()),\n",
    "            'SGDRegressor':self._create_pipeline(SGDRegressor())\n",
    "        }\n",
    "        \n",
    "    def _create_pipeline(self, model):\n",
    "    \n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', model)\n",
    "])\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            \n",
    "            # Metrics \n",
    "            mse = mean_squared_error(self.y_test, y_pred)\n",
    "            mae = mean_absolute_error(self.y_test, y_pred)\n",
    "            r2 = r2_score(self.y_test, y_pred) \n",
    "            \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Mean Squared Error': mse,\n",
    "                'Mean Absolute Error': mae,\n",
    "                'R-squared': r2,\n",
    "                'R-square in %' : f\"{r2*100:.2f}%\"\n",
    "            })\n",
    "        \n",
    "        # Sort by MSE\n",
    "        results_df = pd.DataFrame(results)\n",
    "        display(results_df)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        sns.barplot(x='Model', y='Mean Squared Error',hue = 'Model',\n",
    "                    legend=False, data=results_df, palette='Accent', ax=ax[0])\n",
    "        ax[0].set_title('Model Comparison - Mean Squared Error', size=20)\n",
    "        ax[0].tick_params(axis='x', rotation=45)\n",
    "        ax[0].set_xlabel('Models', size=15)\n",
    "        ax[0].set_ylabel('Mean Squared Errors', size=15)\n",
    "\n",
    "        sns.barplot(x='Model', y='R-squared',hue = 'Model',\n",
    "                    legend=False,palette='pastel', data=results_df, ax=ax[1])\n",
    "        ax[1].set_title('Model Comparison - R-squared', size=20)\n",
    "        ax[1].tick_params(axis='x', rotation=45)\n",
    "        ax[1].set_xlabel('Models', size=15)\n",
    "        ax[1].set_ylabel('R-Squared', size=15)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def predict_best_model(self, X_new):\n",
    "        \n",
    "        # Get the best model based on lowest MSE\n",
    "        results = self.evaluate_models()\n",
    "#        results_df = pd.DataFrame(results)\n",
    "#        display(results_df)\n",
    "#        best_model_name = results_df[['R-squared','Model']]['Model'].max()\n",
    "        best_model_name = results[['Model','R-squared']].sort_values(by = 'R-squared',\n",
    "                                    ascending = False).set_index('Model').index[0]\n",
    "#        best_model_name = results.iloc[0]['Model']\n",
    "        best_model = self.models[best_model_name]\n",
    "        \n",
    "        # Prediction for new data\n",
    "        predictions = best_model.predict(new_data)\n",
    "        \n",
    "        return predictions, best_model_name\n",
    "    \n",
    "    def prediction_error_analysis(self, y_true, y_pred):\n",
    "    \n",
    "        errors = y_true - y_pred\n",
    "        \n",
    "        error_analysis = pd.DataFrame({\n",
    "            'True Values': y_true,\n",
    "            'Predicted Values': y_pred,\n",
    "            'Absolute Errors': np.abs(errors),\n",
    "            'Percentage Errors': np.abs(errors / y_true) * 100\n",
    "        })\n",
    "        \n",
    "        return error_analysis\n",
    "\n",
    "def main():\n",
    "\n",
    "    X = data1.drop(columns='charges')\n",
    "    y = data1.charges\n",
    "    \n",
    "    # Intialize Model Building\n",
    "    predictor = HospitalizationCostPredictor(X, y)\n",
    "    \n",
    "    # Predict using best model\n",
    "    predictions, best_model = predictor.predict_best_model(new_data)\n",
    "    print(f\"\\nPredictions using {best_model}:\")\n",
    "    print(predictions)\n",
    "    \n",
    "    # Error analysis\n",
    "    y_pred = predictor.models[best_model].predict(predictor.X_test)\n",
    "    error_analysis = predictor.prediction_error_analysis(predictor.y_test, y_pred)\n",
    "    print(\"\\nPrediction Error Analysis:\")\n",
    "    print(error_analysis.describe())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
